{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import climin\n",
    "from functools import partial\n",
    "import warnings\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from scipy.linalg.blas import dtrmm\n",
    "\n",
    "import GPy\n",
    "from GPy.util import choleskies\n",
    "from GPy.core.parameterization.param import Param\n",
    "from GPy.kern import Coregionalize\n",
    "from GPy.likelihoods import Likelihood\n",
    "from GPy.util import linalg\n",
    "\n",
    "from likelihoods.bernoulli import Bernoulli\n",
    "from likelihoods.gaussian import Gaussian\n",
    "from likelihoods.categorical import Categorical\n",
    "from likelihoods.hetgaussian import HetGaussian\n",
    "from likelihoods.beta import Beta\n",
    "from likelihoods.gamma import Gamma\n",
    "from likelihoods.exponential import Exponential\n",
    "\n",
    "from hetmogp.util import draw_mini_slices\n",
    "from hetmogp.het_likelihood import HetLikelihood\n",
    "from hetmogp.svmogp import SVMOGP\n",
    "from hetmogp import util\n",
    "from hetmogp.util import vem_algorithm as VEM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import gca\n",
    "from matplotlib import rc, font_manager\n",
    "from matplotlib import rcParams\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "import error_func\n",
    "import click\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi output mode, y_dim: 1\n",
      "\n",
      "Name : SVMOGP\n",
      "Objective : 1651.0470505077521\n",
      "Number of Parameters : 5657\n",
      "Number of Optimization Parameters : 5657\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mSVMOGP.            \u001b[0;0m  |      value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs    \u001b[0;0m  |   (100, 5)  |               |        \n",
      "  \u001b[1mm_u                \u001b[0;0m  |   (100, 1)  |               |        \n",
      "  \u001b[1mL_u                \u001b[0;0m  |  (5050, 1)  |               |        \n",
      "  \u001b[1mkern_q0.variance   \u001b[0;0m  |        1.0  |      +ve      |        \n",
      "  \u001b[1mkern_q0.lengthscale\u001b[0;0m  |       (2,)  |      +ve      |        \n",
      "  \u001b[1mB_q0.W             \u001b[0;0m  |     (2, 1)  |               |        \n",
      "  \u001b[1mB_q0.kappa         \u001b[0;0m  |       (2,)  |      +ve      |        \n",
      "model.kern_q0.lengthscale   \u001b[1mindex\u001b[0;0m  |  SVMOGP.kern_q0.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                  2.00000000  |      +ve      |        \n",
      "  \u001b[1m[1]  \u001b[0;0m  |                  2.00000000  |      +ve      |        \n",
      "Optimiser max iter:  1000\n"
     ]
    }
   ],
   "source": [
    "Q = 1  # number of latent functions\n",
    "mode = 'multi_output'\n",
    "y_dim = 1\n",
    "M = 100\n",
    "\n",
    "x_high = np.load('../data/fertility/x_step1_mean.np')\n",
    "x_low = np.load('../data/fertility/x_step2_mean.np')\n",
    "\n",
    "y_high = np.load('../data/fertility/y_step1_mean.np')\n",
    "y_low = np.load('../data/fertility/y_step2_mean.np')\n",
    "\n",
    "\n",
    "x_high_new = np.zeros((x_high.shape[0], x_high.shape[1]+1))\n",
    "x_high_new[:,0] = x_high[:,1].copy()\n",
    "x_high_new[:,1] = x_high[:,0].copy()\n",
    "x_high_new[:,2] = x_high[:,3].copy() - 15\n",
    "x_high_new[:,3] = x_high[:,2].copy() - 15\n",
    "\n",
    "x_low_new = np.zeros((x_low.shape[0], x_low.shape[1]+1))\n",
    "x_low_new[:,0] = x_low[:,1].copy()\n",
    "x_low_new[:,1] = x_low[:,0].copy()\n",
    "x_low_new[:,2] = x_low[:,3].copy() - 15\n",
    "x_low_new[:,3] = x_low[:,2].copy() - 15\n",
    "\n",
    "x1_high, x2_high, x3_high, x4_high = x_high_new.copy(), x_high_new.copy(), x_high_new.copy(), x_high_new.copy()\n",
    "Y1_high, Y2_high, Y3_high, Y4_high = y_high[:,0].reshape(-1, 1), y_high[:,1].reshape(-1, 1), y_high[:,2].reshape(-1, 1), y_high[:,3].reshape(-1, 1)\n",
    "\n",
    "x1_low, x2_low, x3_low, x4_low = x_low_new.copy(), x_low_new.copy(), x_low_new.copy(), x_low_new.copy()\n",
    "Y1_low, Y2_low, Y3_low, Y4_low = y_low[:,0].reshape(-1, 1), y_low[:,1].reshape(-1, 1), y_low[:,2].reshape(-1, 1), y_low[:,3].reshape(-1, 1)\n",
    "\n",
    "\n",
    "# rnd_idx\n",
    "random.seed(8)\n",
    "size_random_idx = 1000\n",
    "rnd_idx1 = random.sample(range(x1_high.shape[0]), size_random_idx)\n",
    "rnd_idx2 = random.sample(range(x2_high.shape[0]), size_random_idx)\n",
    "\n",
    "# sorted_rnd_idx\n",
    "sorted_rnd_idx1 = np.sort(rnd_idx1)\n",
    "sorted_rnd_idx2 = np.sort(rnd_idx2)\n",
    "\n",
    "X_test1 = x1_high[sorted_rnd_idx1]\n",
    "X_test2 = x2_high[sorted_rnd_idx2]\n",
    "\n",
    "if y_dim == 1:\n",
    "    Y_test = [Y1_high[sorted_rnd_idx1]]\n",
    "elif y_dim == 2:\n",
    "    Y_test = [Y1_high[sorted_rnd_idx1], Y2_high[sorted_rnd_idx2]]\n",
    "\n",
    "x1_high_new = np.delete(x1_high, sorted_rnd_idx1, axis=0)\n",
    "Y1_high_new = np.delete(Y1_high, sorted_rnd_idx1, axis=0)\n",
    "\n",
    "x2_high_new = np.delete(x2_high, sorted_rnd_idx2, axis=0)\n",
    "Y2_high_new = np.delete(Y2_high, sorted_rnd_idx2, axis=0)\n",
    "\n",
    "# Normalising outputs\n",
    "Y1_low_mean = Y1_low.mean().copy()\n",
    "Y1_low_std = Y1_low.std().copy()\n",
    "\n",
    "Y2_low_mean = Y2_low.mean().copy()\n",
    "Y2_low_std = Y2_low.std().copy()\n",
    "\n",
    "Y1_high_mean = Y1_high.mean().copy()\n",
    "Y1_high_std = Y1_high.std().copy()\n",
    "\n",
    "Y2_high_mean = Y2_high.mean().copy()\n",
    "Y2_high_std = Y2_high.std().copy()\n",
    "\n",
    "Y1_low_norm = (Y1_low - Y1_low_mean) / Y1_low_std\n",
    "Y2_low_norm = (Y2_low - Y2_low_mean) / Y2_low_std\n",
    "\n",
    "Y1_high_norm = (Y1_high_new - Y1_high_mean) / Y1_high_std\n",
    "Y2_high_norm = (Y2_high_new - Y2_high_mean) / Y2_high_std\n",
    "\n",
    "random.seed(8+4)\n",
    "high_res_data_random_size = 80\n",
    "rnd_idx_high_res = random.sample(range(x1_high_new.shape[0]), high_res_data_random_size)\n",
    "\n",
    "# sorted_rnd_idx\n",
    "sorted_rnd_idx_high_res = np.sort(rnd_idx_high_res)\n",
    "\n",
    "if mode == 'multi_output':\n",
    "    print('Multi output mode, y_dim:', y_dim)\n",
    "    if y_dim == 1:\n",
    "        X = [x1_high_new[sorted_rnd_idx_high_res], x1_low]\n",
    "        Y = [Y1_high_norm[sorted_rnd_idx_high_res], Y1_low_norm]\n",
    "\n",
    "        #  Creating inducing inputs using cluster centers of the original images\n",
    "        X_ = np.vstack((X[0], X[1]))\n",
    "        \n",
    "        # Heterogeneous Likelihood Definition\n",
    "        likelihoods_list = [Gaussian(sigma=1.), Gaussian(sigma=1.)]\n",
    "    elif y_dim == 2:\n",
    "        X = [x1_high_new[sorted_rnd_idx_high_res], x1_low,\n",
    "             x2_high_new[sorted_rnd_idx_high_res], x2_low]\n",
    "        Y = [Y1_high_norm[sorted_rnd_idx_high_res], Y1_low_norm,\n",
    "             Y2_high_norm[sorted_rnd_idx_high_res], Y2_low_norm]\n",
    "       \n",
    "        #  Creating inducing inputs using cluster centers of the original images\n",
    "        X_ = np.vstack((X[0], X[1], X[2], X[3]))\n",
    "    \n",
    "        # Heterogeneous Likelihood Definition\n",
    "        likelihoods_list = [Gaussian(sigma=1.), Gaussian(sigma=1.), Gaussian(sigma=1.), Gaussian(sigma=1.)]\n",
    "\n",
    "    ls_q = np.array(([2., 2.] * Q))\n",
    "    var_q = np.array(([1.0]*Q))\n",
    "else:\n",
    "    print('Single output mode')\n",
    "    if y_dim == 1:\n",
    "        X = [x1_high_new[sorted_rnd_idx_high_res]]\n",
    "        Y = [Y1_high_norm[sorted_rnd_idx_high_res]]\n",
    "    elif y_dim == 2:\n",
    "        X = [x2_high_new[sorted_rnd_idx_high_res]]\n",
    "        Y = [Y2_high_norm[sorted_rnd_idx_high_res]]\n",
    "        \n",
    "    #  Creating inducing inputs using cluster centers of the original images\n",
    "    X_ = np.vstack((X[0], X[0]))\n",
    "    \n",
    "    # Heterogeneous Likelihood Definition\n",
    "    likelihoods_list = [Gaussian(sigma=1.)]\n",
    "    ls_q = np.array(([2., 2.]*Q))\n",
    "    var_q = np.array(([1.0]*Q))\n",
    "\n",
    "if M > X_.shape[0]:\n",
    "    logging.warning(\"More inducing points than X - setting Z to %d\", X_.shape[0])\n",
    "    M = X_.shape[0]\n",
    "    \n",
    "kmeans_X = KMeans(n_clusters=M, random_state=0).fit(X_)\n",
    "kmeans_X.cluster_centers_.shape\n",
    "Z = kmeans_X.cluster_centers_\n",
    "Z[:,-1] = 1\n",
    "\n",
    "likelihood = HetLikelihood(likelihoods_list)\n",
    "Y_metadata = likelihood.generate_metadata()\n",
    "\n",
    "D = likelihood.num_output_functions(Y_metadata)\n",
    "\n",
    "W_list, _ = util.random_W_kappas(Q, D, rank=1, experiment=True)\n",
    "\n",
    "# KERNELS\n",
    "input_dim = 5\n",
    "\n",
    "kern_list = util.latent_functions_prior(Q, lenghtscale=ls_q, variance=var_q, input_dim=input_dim)\n",
    "\n",
    "model = SVMOGP(X=X, Y=Y, Z=Z, kern_list=kern_list, likelihood=likelihood, Y_metadata=Y_metadata, batch_size=50)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print('model.kern_q0.lengthscale', model.kern_q0.lengthscale)\n",
    "\n",
    "# Z should be fixed, is not implemented\n",
    "model.Z.fix()\n",
    "\n",
    "def transform_y(data_test):\n",
    "    mpred, vpred = model.predict(data_test)\n",
    "    mpred_transformed = []\n",
    "    vpred_transformed = []\n",
    "    if mode == 'multi_output':\n",
    "        for i in range(len(mpred)):\n",
    "            if i % 2 == 1:\n",
    "                continue\n",
    "            if i == 0:\n",
    "                m_pred_star = mpred[i] * Y1_high_std + Y1_high_mean\n",
    "                v_pred_star = vpred[i] * Y1_high_std * Y1_high_std\n",
    "            elif i == 2:\n",
    "                m_pred_star = mpred[i] * Y2_high_std + Y2_high_mean\n",
    "                v_pred_star = vpred[i] * Y2_high_std * Y2_high_std\n",
    "            else:\n",
    "                raise Exception(\"Not implemented!\")\n",
    "            mpred_transformed.append(m_pred_star)\n",
    "            vpred_transformed.append(v_pred_star)\n",
    "    else:\n",
    "        if y_dim == 1:\n",
    "            m_pred_star = mpred[0] * Y1_high_std + Y1_high_mean\n",
    "            v_pred_star = vpred[0] * Y1_high_std * Y1_high_std\n",
    "        elif y_dim == 2:\n",
    "            m_pred_star = mpred[0] * Y2_high_std + Y2_high_mean\n",
    "            v_pred_star = vpred[0] * Y2_high_std * Y2_high_std\n",
    "\n",
    "        mpred_transformed.append(m_pred_star)\n",
    "        vpred_transformed.append(v_pred_star)\n",
    "\n",
    "    return mpred_transformed, vpred_transformed\n",
    "\n",
    "def transform_y_test_set(data_set):\n",
    "    mpred_transformed = []\n",
    "    vpred_transformed = []\n",
    "    if model == 'multi_output':\n",
    "        iters_count = y_dim\n",
    "    else:\n",
    "        iters_count = 1\n",
    "\n",
    "    for i in range(iters_count):\n",
    "        mpred, vpred = model.predict(data_set)\n",
    "        if i == 0:\n",
    "            if mode == 'multi_output':\n",
    "                m_pred_star = mpred[i*2] * Y1_high_std + Y1_high_mean\n",
    "                v_pred_star = vpred[i*2] * Y1_high_std * Y1_high_std\n",
    "            else:\n",
    "                if y_dim == 1:\n",
    "                    m_pred_star = mpred[0] * Y1_high_std + Y1_high_mean\n",
    "                    v_pred_star = vpred[0] * Y1_high_std * Y1_high_std\n",
    "                elif y_dim == 2:\n",
    "                    m_pred_star = mpred[0] * Y2_high_std + Y2_high_mean\n",
    "                    v_pred_star = vpred[0] * Y2_high_std * Y2_high_std\n",
    "        elif i == 1:\n",
    "            assert mode == 'multi_output'\n",
    "            m_pred_star = mpred[i*2] * Y2_high_std + Y2_high_mean\n",
    "            v_pred_star = vpred[i*2] * Y2_high_std * Y2_high_std\n",
    "        else:\n",
    "            raise Exception(\"Not implemented!\")\n",
    "\n",
    "        mpred_transformed.append(m_pred_star)\n",
    "        vpred_transformed.append(v_pred_star)\n",
    "\n",
    "    return mpred_transformed, vpred_transformed\n",
    "\n",
    "\n",
    "def error_calc(data_test, true_labels, calculate_snlp=False, test_mode=False, Y_train_snlp=None, \n",
    "               single_dim_only=False):\n",
    "    if test_mode == False:\n",
    "        m_pred_star, v_pred_star = transform_y(data_test)\n",
    "    else:\n",
    "# if test_mode is set, means that we want inference for test set data, x is shared, y is a list of y1, y2, ...\n",
    "        m_pred_star, v_pred_star = transform_y_test_set(data_test)\n",
    "\n",
    "    smse_error = error_func.smse(mu_star_list=m_pred_star, Y_test_list=true_labels)\n",
    "    if calculate_snlp:\n",
    "        if single_dim_only:\n",
    "            snlp_error = error_func.snlp(mu_star_list=[m_pred_star[0]], var_star_list=[v_pred_star[0]], \n",
    "                                         Y_test_list=true_labels, Y_train_list=Y_train_snlp)\n",
    "        else:\n",
    "            snlp_error = error_func.snlp(mu_star_list=m_pred_star, var_star_list=v_pred_star, \n",
    "                                         Y_test_list=true_labels, Y_train_list=Y_train_snlp)\n",
    "\n",
    "    else:\n",
    "        snlp_error = None\n",
    "        msll_error = None\n",
    "    return smse_error, snlp_error\n",
    "\n",
    "max_iter = 1000\n",
    "print(\"Optimiser max iter: \", max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svi - iteration 100/1000:[[-1457.20677999]]\n",
      "svi - iteration 200/1000:[[-1218.87779029]]\n",
      "svi - iteration 300/1000:[[-983.52022031]]\n",
      "svi - iteration 400/1000:[[-871.14472836]]\n",
      "svi - iteration 500/1000:[[-808.53632294]]\n",
      "svi - iteration 600/1000:[[-803.52985688]]\n",
      "svi - iteration 700/1000:[[-853.80240453]]\n",
      "svi - iteration 800/1000:[[-831.94530008]]\n",
      "svi - iteration 900/1000:[[-810.09994718]]\n",
      "svi - iteration 1000/1000:[[-775.16090062]]\n",
      "--- 2523.0613961219788 seconds ---\n",
      "Test SMSE: [0.04392279]\n",
      "Test SNLP: [-3.68148376]\n",
      "***********************************************************************\n",
      "\n",
      "Name : SVMOGP\n",
      "Objective : 772.1801584682671\n",
      "Number of Parameters : 5657\n",
      "Number of Optimization Parameters : 5157\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mSVMOGP.            \u001b[0;0m  |               value  |  constraints  |  priors\n",
      "  \u001b[1minducing_inputs    \u001b[0;0m  |            (100, 5)  |     fixed     |        \n",
      "  \u001b[1mm_u                \u001b[0;0m  |            (100, 1)  |               |        \n",
      "  \u001b[1mL_u                \u001b[0;0m  |           (5050, 1)  |               |        \n",
      "  \u001b[1mkern_q0.variance   \u001b[0;0m  |  0.4221733527473745  |      +ve      |        \n",
      "  \u001b[1mkern_q0.lengthscale\u001b[0;0m  |                (2,)  |      +ve      |        \n",
      "  \u001b[1mB_q0.W             \u001b[0;0m  |              (2, 1)  |               |        \n",
      "  \u001b[1mB_q0.kappa         \u001b[0;0m  |                (2,)  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "def callback(i):\n",
    "    if i['n_iter'] % 100 == 0:\n",
    "        print('svi - iteration ' + str(i['n_iter']) + '/' + str(max_iter) + \":\" + (str(model.log_likelihood())))\n",
    "\n",
    "        # Note that X_test is numpy array, and Y_test is a list\n",
    "        if y_dim == 1:\n",
    "            test_smse_error, test_snlp_error = error_calc(X_test1, Y_test, calculate_snlp=True, \n",
    "                                                                test_mode=True, \n",
    "                                                                Y_train_snlp=Y)\n",
    "\n",
    "        elif y_dim == 2:                \n",
    "            if mode == 'multi_output':\n",
    "                test_smse_error_y1, test_snlp_error_y1 = error_calc(X_test1, [Y_test[0]], \n",
    "                                                                                       calculate_snlp=True, \n",
    "                                                                                       test_mode=True,\n",
    "                                                                                       Y_train_snlp=[Y[0]],\n",
    "                                                                                       single_dim_only=True)\n",
    "                test_smse_error_y2, test_snlp_error_y2 = error_calc(X_test2, [Y_test[1]], \n",
    "                                                                                       calculate_snlp=True, \n",
    "                                                                                       test_mode=True,\n",
    "                                                                                       Y_train_snlp=[Y[2]],\n",
    "                                                                                       single_dim_only=True)\n",
    "                test_smse_error = (test_smse_error_y1 + test_smse_error_y2) / 2.0\n",
    "                test_snlp_error = (test_snlp_error_y1 + test_snlp_error_y2) / 2.0\n",
    "\n",
    "\n",
    "            else:\n",
    "                if y_dim == 1:\n",
    "                    test_smse_error, test_snlp_error = error_calc(X_test1, Y_test, \n",
    "                                                                        calculate_snlp=True, \n",
    "                                                                        test_mode=True, Y_train_snlp=Y)\n",
    "                elif y_dim == 2:\n",
    "                    test_smse_error, test_snlp_error = error_calc(X_test2, [Y_test[1]], \n",
    "                                                                        calculate_snlp=True, \n",
    "                                                                        test_mode=True, Y_train_snlp=Y)\n",
    "\n",
    "    if i['n_iter'] > max_iter:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "start_time = time.time()\n",
    "opt = climin.Adam(model.optimizer_array, model.stochastic_grad, step_rate=0.01, decay_mom1=1 - 0.9, \n",
    "                  decay_mom2=1 - 0.999)\n",
    "\n",
    "opt.minimize_until(callback)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "test_smse_error, test_snlp_error = error_calc(X_test1, Y_test, calculate_snlp=True, \n",
    "                                                                test_mode=True, \n",
    "                                                                Y_train_snlp=Y)\n",
    "\n",
    "print(\"Test SMSE:\", test_smse_error)\n",
    "print(\"Test SNLP:\", test_snlp_error)\n",
    "print(\"***********************************************************************\")\n",
    "\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
